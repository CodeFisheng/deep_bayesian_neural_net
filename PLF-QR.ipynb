{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters .............\n",
      "loading data ...........\n",
      "reach max file number\n"
     ]
    }
   ],
   "source": [
    "############################# this code unfinished #######################\n",
    "# seperately apply marginal interal sampling on different households\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import random as rd\n",
    "import argparse\n",
    "import os, sys\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as pl\n",
    "from numpy import random, histogram2d, diff\n",
    "from scipy.interpolate import interp2d\n",
    "#%matplotlib inline\n",
    "# class County:\n",
    "#     def __init__(self,parsename):\n",
    "#         self.parsename = parsename\n",
    "#         dataframe = xls.parse(parsename)\n",
    "#         self.data = dataframe\n",
    "#     def disp_all(self):\n",
    "#         print self.dataframe\n",
    "#     def get_all(self):\n",
    "#         return self.dataframe\n",
    "# xls = pd.ExcelFile('No-drybulb-dewpoint-short-dataset-CT.xlsx',header = None)\n",
    "# Zonal = []\n",
    "# Zonal.append(County('CT'))\n",
    "# ZonalNum = 1\n",
    "\n",
    "print \"setting parameters .............\"\n",
    "num_epochs = 1000 # training epoches for each customer samples\n",
    "num_realisations = 5000\n",
    "out_thresh = num_epochs - 100\n",
    "day_steps_f = 48\n",
    "#val_rate_f = 0.15\n",
    "test_batch_size_f = 28*day_steps_f # days of a batch\n",
    "valid_batch_size_f = 28*day_steps_f\n",
    "train_batch_size_f = 28*day_steps_f\n",
    "n_output_f = 1\n",
    "n_hidden_f_1 = 100\n",
    "n_hidden_f_2 = 100\n",
    "n_hidden_f_3 = 100\n",
    "n_hidden_f_4 = 100\n",
    "tao_f = 0.1\n",
    "gap_test_f = 10\n",
    "batch_size_f = test_batch_size_f # in this version, batch_size set same\n",
    "preserve_f = 0#16114 ## amount of first time points without complete features\n",
    "_dropout_train = 0.5\n",
    "_dropout_test = 1.0\n",
    "ZonalNum = 1\n",
    "# DEMAND MATRIX 9 X LENGTH, 9: INC is total, index with 0, other substations are from 1 -> 8\n",
    "\n",
    "\n",
    "\n",
    "############################||||||||||||||||||||||||||data loading\n",
    "\n",
    "print \"loading data ...........\"\n",
    "#ISO_name = 'No-drybulb-dewpoint-short-dataset-CT.csv'\n",
    "#HOME_name = 'data/MAC005540.csv'\n",
    "count = 0\n",
    "hid = 0\n",
    "for root, dirs, filenames in os.walk('./data/'):\n",
    "    for fname in filenames:\n",
    "        dbslice = pd.read_csv('./data/' + fname)\n",
    "        if count < hid:\n",
    "            count = count +1\n",
    "            continue;\n",
    "        if count == hid:\n",
    "            xls = dbslice\n",
    "        else:\n",
    "            xls = pd.concat([xls,dbslice], axis = 0)\n",
    "        count = count + 1\n",
    "        if count > hid:\n",
    "            print 'reach max file number'\n",
    "            break;\n",
    "xls.shape\n",
    "rows_f = xls.shape[0]\n",
    "columns_f = xls.shape[1]\n",
    "database_f = np.array(xls)\n",
    "np.random.shuffle(database_f)\n",
    "for i in range(rows_f):\n",
    "    for j in range(columns_f):\n",
    "        database_f[i,j] = np.float(database_f[i,j])\n",
    "totalen_f = rows_f\n",
    "#print database_f[:,0]\n",
    "n_input_f = columns_f - 1\n",
    "data_norm = np.max(database_f, axis = 0)\n",
    "database_f = database_f/data_norm\n",
    "#print totalen_f\n",
    "db_f = database_f\n",
    "#print db_f\n",
    "#define id arrays\n",
    "test_id_f = np.array(test_batch_size_f)\n",
    "valid_id_f = np.array(2*valid_batch_size_f)\n",
    "train_id_f = np.array(totalen_f - test_batch_size_f - valid_batch_size_f)\n",
    "\n",
    "#give values to id arrays\n",
    "rang = range(preserve_f, totalen_f - test_batch_size_f)\n",
    "valid_id_f = rd.sample(rang,2*valid_batch_size_f)\n",
    "test_id_f = np.array(range(totalen_f - test_batch_size_f,totalen_f))\n",
    "train_id_f = set(range(preserve_f, totalen_f - test_batch_size_f)) - set(valid_id_f)\n",
    "\n",
    "#sort three id array\n",
    "valid_id_f = np.sort(valid_id_f)\n",
    "test_id_f = np.sort(test_id_f)\n",
    "train_id_f = np.array(list(train_id_f))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset = xls[-48*28:]\n",
    "trainset = xls[0:-48*28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5641\n",
      "14.8784\n",
      "21.2331\n",
      "26.5136\n",
      "30.9246\n",
      "34.3252\n",
      "36.8348\n",
      "37.0776\n",
      "31.1656\n",
      "26.7241081096\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "mod = smf.quantreg('Power ~ monday + tuesday + wednesday + thursday + \\\n",
    "friday + saturday + holiday+ temperature + humidity + windspeed + rainfall+\\\n",
    "h1 + h2 + h3 + h4 + h5 + h6 + h9 + h10 + h11 + h12 + h13 + h14 + h15 + h16 \\\n",
    "+ h17 + h18 + h19 + h20 + h21 + h22 + h23 + h24+ july + aug + sep + jan + feb + mar\\\n",
    "+apr + may + june ', trainset)\n",
    "def pinball_loss(A,B,tao):\n",
    "\tcost = 0.0\n",
    "\tA = A.reshape([-1])\n",
    "\tB = B.reshape([-1])\n",
    "\tfor i in range(A.shape[0]):\n",
    "\t    if A[i]-B[i]>=0:\n",
    "\t        tmp = (A[i]-B[i])*(tao)\n",
    "\t    else:\n",
    "\t        tmp = (B[i]-A[i])*(1.0-tao)\n",
    "\t    cost = tmp+cost\n",
    "\treturn cost\n",
    "quantiles = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "\n",
    "# get all result instances in a list\n",
    "res_all = [mod.fit(q=q) for q in quantiles]\n",
    "Plist = []\n",
    "ind = 0\n",
    "totalpb = 0\n",
    "for qm, res in zip(quantiles, res_all):\n",
    "    # get prediction for the model and plot\n",
    "\tqforecasts = res.predict({'jan': testset['jan'], 'feb': testset['feb'], 'mar': testset['mar'], \\\n",
    "    'apr': testset['apr'], 'may': testset['may'], 'june': testset['june'], \\\n",
    "    'july': testset['july'], 'aug': testset['aug'], 'sep': testset['sep'], \\\n",
    "    'temperature': testset['temperature'], 'humidity': testset['humidity'], 'windspeed': testset['windspeed'], \\\n",
    "    'rainfall': testset['rainfall'],'monday': testset['monday'], 'tuesday': testset['tuesday'], \\\n",
    "    'h1': testset['h1'], 'h2': testset['h2'], 'h3': testset['h3'], \\\n",
    "    'h4': testset['h4'], 'h5': testset['h5'], 'h6': testset['h6'], \\\n",
    "    'h7': testset['h7'], 'h8': testset['h8'], 'h9': testset['h9'], \\\n",
    "    'h10': testset['h10'], 'h11': testset['h11'], 'h12': testset['h12'], \\\n",
    "    'h13': testset['h13'], 'h14': testset['h14'], 'h15': testset['h15'], \\\n",
    "    'h16': testset['h16'], 'h17': testset['h17'], 'h18': testset['h18'], \\\n",
    "    'h19': testset['h19'], 'h20': testset['h20'], 'h21': testset['h21'], \\\n",
    "    'h22': testset['h22'], 'h23': testset['h23'], 'h24': testset['h24'], \\\n",
    "    'wednesday': testset['wednesday'], 'thursday': testset['thursday'], 'friday': testset['friday']\\\n",
    "    , 'saturday': testset['saturday'], 'holiday': testset['holiday']})\n",
    "\tPlist.append(qforecasts)\n",
    "\tloss_pb = pinball_loss(testset['Power'], qforecasts, qm)\n",
    "\tprint '%.4f'%(loss_pb)\n",
    "\ttotalpb = totalpb + loss_pb\n",
    "print totalpb/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codefisheng/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:32: FutureWarning: \n",
      "The default value for 'return_type' will change to 'axes' in a future release.\n",
      " To use the future behavior now, set return_type='axes'.\n",
      " To keep the previous behavior and silence this warning, set return_type='dict'.\n"
     ]
    }
   ],
   "source": [
    "print 'Visualization'\n",
    "N = 1\n",
    "x = np.linspace(0, 336, 336)\n",
    "oneday_x = x\n",
    "vals = [1,2,3,4] # Values to iterate over and add/subtract from y.\n",
    "pl.rc('font', family='serif')\n",
    "fig = pl.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xlabel('The x values')\n",
    "ax.set_ylabel('The y values')\n",
    "#ax.set_ylim([0,1.8])\n",
    "pl.rc('font', family = 'serif', serif = 'Times')\n",
    "pl.rc('xtick', labelsize = 8)\n",
    "pl.rc('ytick', labelsize = 8)\n",
    "pl.rc('axes', labelsize = 8)\n",
    "#################################### one day case\n",
    "#for i, val in enumerate(vals):\n",
    "#    alpha = 0.5*(i+1)/len(vals) # Modify the alpha value for each iteration.\n",
    "#    if i == 0:\n",
    "#        ax.fill_between(oneday_x, Plist[8][0:336], Plist[0][0:336], color='red', alpha=alpha*0.7)\n",
    "#    elif i == 1:\n",
    "#        ax.fill_between(oneday_x, Plist[7][0:336], Plist[1][0:336], color='red', alpha=alpha*0.7)\n",
    "#    elif i == 2:\n",
    "#        ax.fill_between(oneday_x, Plist[6][0:336], Plist[2][0:336], color='red', alpha=alpha*0.7)\n",
    "#    else:\n",
    "#        ax.fill_between(oneday_x, Plist[5][0:336], Plist[3][0:336], color='red', alpha=alpha*0.7)\n",
    "ax.plot(oneday_x/48+0.5, testset['Power'][0:336], '-', color='black',linewidth=1.) # Plot the original signal\n",
    "boxP = np.array(Plist)\n",
    "boxP = boxP.T\n",
    "boxP = boxP.reshape([7,-1])\n",
    "boxP = boxP.T\n",
    "pd.DataFrame(boxP).boxplot()\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codefisheng/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: FutureWarning: \n",
      "The default value for 'return_type' will change to 'axes' in a future release.\n",
      " To use the future behavior now, set return_type='axes'.\n",
      " To keep the previous behavior and silence this warning, set return_type='dict'.\n"
     ]
    }
   ],
   "source": [
    "boxP = np.array(Plist)\n",
    "boxP = boxP.T\n",
    "boxP = boxP.reshape([7,-1])\n",
    "boxP = boxP.T\n",
    "pd.DataFrame(boxP).boxplot()\n",
    "ax.plot(oneday_x/48, testset['Power'][0:336], color='black') # Plot the original signal\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help(pl.boxplot())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
